{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duckietown/duckietown-lx-recipes/blob/mooc2022/object-detection/assets/colab/dt_object_detection_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mIJd6b6pbsk"
      },
      "source": [
        "# First, let us set up a few dependencies\n",
        "\n",
        "Don't forget to switch to a GPU-enabled colab runtime!\n",
        "\n",
        "```\n",
        "Runtime -> Change Runtime Type -> GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2APl4pnbAa"
      },
      "source": [
        "import os\n",
        "import contextlib\n",
        "@contextlib.contextmanager\n",
        "def directory(name):\n",
        "  ret = os.getcwd()\n",
        "  os.chdir(name)\n",
        "  yield None\n",
        "  os.chdir(ret)\n",
        "\n",
        "import subprocess\n",
        "def run(input, exception_on_failure=False):\n",
        "  try:\n",
        "    program_output = subprocess.check_output(f\"{input}\", shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
        "  except Exception as e:\n",
        "    if exception_on_failure:\n",
        "      raise e\n",
        "    program_output = e.output\n",
        "\n",
        "    return program_output\n",
        "def prun(input, exception_on_failure=False):\n",
        "  x = run(input, exception_on_failure)\n",
        "  print(x)\n",
        "  return x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6gJLjcipgNw"
      },
      "source": [
        "# This mounts your google drive to this notebook. You might have to change the path to fit with your dataset folder inside your drive.\n",
        "\n",
        "Read the instruction output by the cell bellow carefully!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu1Y8D2jINNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c738518-1408-45ef-a081-4f3eee1b4ed8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with directory(\"/content/drive/My Drive/duckietown_object_detection_dataset\"):\n",
        "  print(os.getcwd())\n",
        "  print(os.listdir())\n",
        "\n",
        "os.chdir('/content/drive/My Drive/duckietown_object_detection_dataset')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/duckietown_object_detection_dataset\n",
            "['train', 'frames', 'labels', 'annotation', 'val', 'images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0GPE6WDIV0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a704e8-085f-4854-e1dd-ee1ef90a4ab2"
      },
      "source": [
        "\n",
        "if not os.path.exists(\"SENTINEL\"):\n",
        "  prun(\"mkdir duckietown_object_detection_dataset\")\n",
        "  prun(\"mv train duckietown_object_detection_dataset && mv val duckietown_object_detection_dataset\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4VMcwmpr84"
      },
      "source": [
        "# Next, we will clone Yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8L68QAeZF9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b5f85d-ecb9-475f-be67-c73bb208f8c5"
      },
      "source": [
        "!git clone https://github.com/duckietown/yolov5.git -b dt-obj-det\n",
        "!cd yolov5 && pip3 install -r requirements.txt\n",
        "!pip3 install torch==1.11 torchvision==0.12.0\n",
        "if not os.path.exists(\"SENTINEL\"):\n",
        "  run(\"mv duckietown_object_detection_dataset yolov5\")\n",
        "!touch SENTINEL"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 6162, done.\u001b[K\n",
            "remote: Total 6162 (delta 0), reused 0 (delta 0), pack-reused 6162\u001b[K\n",
            "Receiving objects: 100% (6162/6162), 8.47 MiB | 11.72 MiB/s, done.\n",
            "Resolving deltas: 100% (4212/4212), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (0.13.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 15)) (2.9.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 19)) (0.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 20)) (1.3.5)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 29)) (2.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.8.1->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.14.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.50.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.38.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 20)) (2022.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.2.2)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.11\n",
            "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 18 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.12.0\n",
            "  Downloading torchvision-0.12.0-cp38-cp38-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.11) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0) (3.0.4)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.11.0 torchvision-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We can now inform the training process of the format and location of our dataset"
      ],
      "metadata": {
        "id": "g5iilV-e76YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./yolov5/data/duckietown.yaml\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ../train\n",
        "val: ../val\n",
        "\n",
        "# number of classes\n",
        "nc: 4\n",
        "\n",
        "# class names\n",
        "names: [ 'duckie', 'cone', 'truck', 'bus' ]"
      ],
      "metadata": {
        "id": "7u3D124u8Flw",
        "outputId": "bceb1fd7-f62b-418a-acf3-2456a308d0c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./yolov5/data/duckietown.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalmQI9Ypx5v"
      },
      "source": [
        "# And we're ready to train! This step will take a hour or so.\n",
        "\n",
        "Notice that we're only training for 10 epochs. That's probably not enough!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kss7Oid6OkAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e4fea4-4236-4470-836c-43102bf13dd6"
      },
      "source": [
        "!mv yolov5/best.pt yolov5/best_old.pt\n",
        "!cd yolov5 && python3 train.py --img 416 --batch 16 --epochs 10 --data duckietown.yaml --weights yolov5s.pt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'yolov5/best.pt': No such file or directory\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/duckietown/yolov5 ✅\n",
            "YOLOv5 🚀 v5.0-68-ge6681ef torch 1.11.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='./data/duckietown.yaml', device='', entity=None, epochs=10, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp3', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov5s.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 283 layers, 7071633 parameters, 7071633 gradients, 16.5 GFLOPS\n",
            "\n",
            "Transferred 356/362 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 62 .bias, 62 conv.weight, 59 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train/labels' images and labels... 804 found, 0 missing, 0 empty, 0 corrupted: 100% 804/804 [09:20<00:00,  1.44it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../val/labels' images and labels... 202 found, 0 missing, 0 empty, 0 corrupted: 100% 202/202 [02:20<00:00,  1.44it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../val/labels.cache\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.94, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 416 train, 416 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp3\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/9    0.864G    0.1253   0.01913   0.04041    0.1849        19       416: 100% 51/51 [00:18<00:00,  2.78it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.70it/s]\n",
            "                 all         202         558      0.0117     0.00797    0.000648    9.52e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/9     1.42G   0.09979   0.02155   0.02237    0.1437        15       416: 100% 51/51 [00:16<00:00,  3.00it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.82it/s]\n",
            "                 all         202         558       0.595       0.108       0.059      0.0109\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/9     1.42G   0.07826   0.02436   0.01392    0.1165         9       416: 100% 51/51 [00:17<00:00,  2.95it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  3.08it/s]\n",
            "                 all         202         558       0.736       0.243        0.22      0.0651\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       3/9     1.42G   0.07146   0.02061    0.0121    0.1042         4       416: 100% 51/51 [00:17<00:00,  3.00it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.73it/s]\n",
            "                 all         202         558       0.822       0.253       0.299        0.12\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       4/9     1.42G   0.06614   0.02005  0.009737   0.09594         3       416: 100% 51/51 [00:16<00:00,  3.02it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  3.06it/s]\n",
            "                 all         202         558       0.892       0.338       0.462       0.196\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       5/9     1.42G   0.06028   0.01825  0.007783   0.08632        13       416: 100% 51/51 [00:16<00:00,  3.00it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.88it/s]\n",
            "                 all         202         558       0.495       0.632       0.538       0.222\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       6/9     1.42G   0.05572   0.01789  0.005583   0.07919         7       416: 100% 51/51 [00:17<00:00,  2.96it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  3.20it/s]\n",
            "                 all         202         558        0.74       0.629       0.677       0.314\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       7/9     1.42G   0.05174   0.01699   0.00459   0.07332        18       416: 100% 51/51 [00:16<00:00,  3.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  3.08it/s]\n",
            "                 all         202         558       0.739       0.584       0.624       0.274\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       8/9     1.42G   0.04766   0.01655   0.00346   0.06767        10       416: 100% 51/51 [00:16<00:00,  3.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  3.30it/s]\n",
            "                 all         202         558       0.817       0.699       0.754       0.396\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       9/9     1.42G   0.04632   0.01538  0.003185   0.06488         7       416: 100% 51/51 [00:16<00:00,  3.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  1.86it/s]\n",
            "                 all         202         558       0.608       0.711       0.648       0.287\n",
            "              duckie         202         502         0.5       0.833       0.652       0.289\n",
            "                cone         202          56       0.717       0.589       0.645       0.285\n",
            "10 epochs completed in 0.058 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp3/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp3/weights/best.pt, 14.4MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "all_exps = os.listdir(\"yolov5/runs/train\")\n",
        "all_exps_filtered = map(lambda x: int(x.replace(\"exp\", \"1\")), filter(lambda x: x.startswith(\"exp\"), all_exps))\n",
        "all_exps_filtered = np.array(list(all_exps))\n",
        "latest_exp_index = np.argmax(all_exps)\n",
        "latest_exp = all_exps[latest_exp_index]\n",
        "print(f\"Latest exp is {latest_exp}\")\n",
        "\n",
        "prun(f\"cp yolov5/runs/train/{latest_exp}/weights/best.pt yolov5/best.pt\")"
      ],
      "metadata": {
        "id": "b5jSQ4XubFqH",
        "outputId": "d0a40fb2-8653-4274-c7bb-cc2b7ce5c8dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest exp is exp3\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz2PZ7d0qPt0"
      },
      "source": [
        "# Next, we can upload your model to Duckietown's cloud!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bNXEgAFpRIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af34c79b-a15e-4695-acc9-7cf8d1d5582f"
      },
      "source": [
        "!pip3 install git+https://github.com/duckietown/lib-dt-mooc-2021"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/duckietown/lib-dt-mooc-2021\n",
            "  Cloning https://github.com/duckietown/lib-dt-mooc-2021 to /tmp/pip-req-build-fcddid85\n",
            "  Running command git clone -q https://github.com/duckietown/lib-dt-mooc-2021 /tmp/pip-req-build-fcddid85\n",
            "Collecting dt-data-api-daffy>=0.1.8\n",
            "  Downloading dt-data-api-daffy-1.1.3.tar.gz (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from dt-data-api-daffy>=0.1.8->dt-mooc-2021==0.0.0) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from dt-data-api-daffy>=0.1.8->dt-mooc-2021==0.0.0) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from dt-data-api-daffy>=0.1.8->dt-mooc-2021==0.0.0) (4.9.1)\n",
            "Collecting dt-authentication-daffy\n",
            "  Downloading dt-authentication-daffy-0.1.16.tar.gz (3.3 kB)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting ecdsa\n",
            "  Downloading ecdsa-0.18.0-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from ecdsa->dt-authentication-daffy->dt-data-api-daffy>=0.1.8->dt-mooc-2021==0.0.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->dt-data-api-daffy>=0.1.8->dt-mooc-2021==0.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->dt-data-api-daffy>=0.1.8->dt-mooc-2021==0.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->dt-data-api-daffy>=0.1.8->dt-mooc-2021==0.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->dt-data-api-daffy>=0.1.8->dt-mooc-2021==0.0.0) (2022.9.24)\n",
            "Building wheels for collected packages: dt-mooc-2021, dt-data-api-daffy, dt-authentication-daffy\n",
            "  Building wheel for dt-mooc-2021 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-mooc-2021: filename=dt_mooc_2021-0.0.0-py3-none-any.whl size=6447 sha256=c5a28454b046516c1a2b35bcb7225ad0d9e55167caf5f8bfad62a7ac4385603b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pjw9lrp7/wheels/d5/df/21/aa957c23320a8241d9197289a987390c37adce3463c5ef9df8\n",
            "  Building wheel for dt-data-api-daffy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-data-api-daffy: filename=dt_data_api_daffy-1.1.3-py3-none-any.whl size=13714 sha256=1a15ce669a72ef8ea7c8333a18f1eaf3e15b3dd873df59c43946b88ced02f8a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/ce/fb/5a988e5766d210a7586879219893e14a85ebca9f179ee91041\n",
            "  Building wheel for dt-authentication-daffy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-authentication-daffy: filename=dt_authentication_daffy-0.1.16-py3-none-any.whl size=3432 sha256=333d7b47f47156a8270f85e255d6dd7d3181e817e970b30faf8af2b1db9e1488\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/a0/1c/f2cfd43e7989e84af4ddc942406e6716c5aaf98cddcda8da54\n",
            "Successfully built dt-mooc-2021 dt-data-api-daffy dt-authentication-daffy\n",
            "Installing collected packages: ecdsa, base58, dt-authentication-daffy, dt-data-api-daffy, dt-mooc-2021\n",
            "Successfully installed base58-2.1.1 dt-authentication-daffy-0.1.16 dt-data-api-daffy-1.1.3 dt-mooc-2021-0.0.0 ecdsa-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3HWb4wMpZc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "bcad279a-ddf1-4a6b-a9a7-7b8ca49d91b0"
      },
      "source": [
        "from dt_mooc.cloud import Storage\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "def select_device(device='', batch_size=None):\n",
        "    import torch\n",
        "    # device = 'cpu' or '0' or '0,1,2,3'\n",
        "    cpu = device.lower() == 'cpu'\n",
        "    if cpu:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False\n",
        "    elif device:  # non-cpu device requested\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable\n",
        "        assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # check availability\n",
        "\n",
        "    cuda = not cpu and torch.cuda.is_available()\n",
        "\n",
        "    return torch.device('cuda:0' if cuda else 'cpu')\n",
        "\n",
        "sys.path.insert(0, './yolov5')\n",
        "model = torch.load(\"./yolov5/best.pt\", map_location=select_device(\"cpu\"))['model'].float()  # load to FP32\n",
        "model.to(select_device(\"cpu\")).eval()\n",
        "\n",
        "storage = Storage(\"YOUR_DUCKIETOWN_TOKEN_HERE\")\n",
        "\n",
        "storage.upload_yolov5(\"yolov5\", model, \"./yolov5/best.pt\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <progress\n",
              "                value='100'\n",
              "                max='100',\n",
              "                style='width: 100%'\n",
              "            >\n",
              "                100\n",
              "            </progress>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file `best.pt`...\n",
            "\n",
            "File `best.pt` successfully uploaded! It will now be found at `courses/mooc/2021/data/nn_models/yolov5.pt`.\n",
            "Uploading file `best.pt.wts`...\n",
            "\n",
            "File `best.pt.wts` successfully uploaded! It will now be found at `courses/mooc/2021/data/nn_models/yolov5.wts`.\n",
            "Uploading file `best.pt.wts.sha256`...\n",
            "\n",
            "File `best.pt.wts.sha256` successfully uploaded! It will now be found at `courses/mooc/2021/data/nn_models/yolov5.sha256`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUVJ5BfBGq7F"
      },
      "source": [
        "# Done!\n",
        "\n",
        "We're done training! You can go back to the `Training` notebook"
      ]
    }
  ]
}